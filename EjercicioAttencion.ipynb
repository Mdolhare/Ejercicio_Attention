{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":18566,"status":"ok","timestamp":1695928519983,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"m-4H1hfGCMK5"},"outputs":[],"source":["from sklearn.datasets import fetch_20newsgroups\n","from matplotlib import pyplot as plt\n","from collections import Counter\n","newsgroups_train = fetch_20newsgroups(subset='train')\n","newsgroups_test = fetch_20newsgroups(subset='test')\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import gensim\n","from gensim.models import KeyedVectors\n","import os, re, csv, math, codecs"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6879,"status":"ok","timestamp":1695928526855,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"DHkEhU4zCUmn"},"outputs":[],"source":["token=Tokenizer(num_words=30000,\n","                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n","                split=' ', char_level=False, oov_token=\"UNK\", document_count=0)\n","token.fit_on_texts(newsgroups_train.data)\n","train_sequences=token.texts_to_sequences(newsgroups_train.data)\n","test_sequences=token.texts_to_sequences(newsgroups_test.data)\n","lengths=[len(seq) for seq in train_sequences]\n","lengths=dict(Counter(lengths))\n","max_len=500 #Incluso si algunos textos son mas largos, tener las primeras 500 palabras es suficiente en la clasificacion de textos\n","train_sequences=pad_sequences(train_sequences,maxlen=max_len)   #Las primeras palabras suelen contener toda la informacion nesesaria para la clasificacion\n","test_sequences=pad_sequences(test_sequences,maxlen=max_len)\n","reverse_dictionary = token.index_word\n","dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23939,"status":"ok","timestamp":1695928550784,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"v7Y0eL8TCsNn","outputId":"8380e2b7-f9a3-4f61-c01f-772812c03367"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73235,"status":"ok","timestamp":1695928627290,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"qUEoCGLMCstu","outputId":"b4447119-46ef-4c12-91cb-91679dc0baea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  drive/MyDrive/crawl-300d-2M.vec.zip\n","  inflating: crawl-300d-2M.vec       \n"]}],"source":["!unzip 'drive/MyDrive/crawl-300d-2M.vec.zip'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":453065,"status":"ok","timestamp":1695929080338,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"oSEC-PPVC1fB"},"outputs":[],"source":["#Se utilizan los embeddigns de facebook pre-entrenados con Common Crawl\n","embeddings_index = KeyedVectors.load_word2vec_format('crawl-300d-2M.vec',\n","                                                     binary=False)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1695929080339,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"ctACqILWC3Ry"},"outputs":[],"source":["embed_dim=300\n","num_words=len(dictionary)+1\n","embedding_matrix=np.zeros([num_words,embed_dim])\n","for word, idx in dictionary.items():\n","  if idx <= num_words and word in embeddings_index:\n","    embedding_matrix[idx,:]=embeddings_index[word]"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1695929080340,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"1y53XiOkE6QM"},"outputs":[],"source":["from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, MaxPooling1D, Dropout, Dense, Input, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Flatten, BatchNormalization, Activation, Bidirectional, LSTM, Reshape\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.activations import softmax\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import optimizers"]},{"cell_type":"markdown","metadata":{"id":"PQK19DbyP1Ll"},"source":["# Red de attention + conv\n","### Parte convolucional:\n","Se utiliza una red convolucional luego de la capa de embeddings para optener una representacion de la palabra que incluya su contexto, es decir que a la salida se tienen vectores de dimencion 100 los cuales puede comprender un significado de la palabra en base a las palabras en su alrededor. La funcion tangente hyperbolica a la salida de la ultima capa convolucional se utiliza para escalar la salida. Se quiere valores pequeÃ±os a la salida para evitar problemas de baja gradiente en la funcion softmax.\n","\n","### Mecanismo de attention\n","Dado que se quiere clasificar en distintas clases, en este caso necesitamos un mequanismo que sepa reconocer que palabras son relevantes para la clasificacion y cuales no. Por lo tanto, hay solo una preguntar para hacer (si la palabra es relevante o no) y esto lleva a que haya un solo vector de query, el cual se obtiene durante el entrenamiento de la capa.\n","Luego de obtener la representacion ponderada de cada palabra estas se suman para obtener la representacion ponderada del texto completo. No es necesario dividir el total por la cantidad de palabras ya que en el preprocesamiento se dejaron todos los vectores de textos con la misma dimencionalidad.\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":522,"status":"ok","timestamp":1695929310093,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"jO1pjpewC5Qv"},"outputs":[],"source":["value_dim=100\n","nb_words=num_words\n","num_filters=64\n","input_layer = Input(shape=(max_len,))\n","embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n","\n","#Capa convolucional\n","conv_out=Conv1D(value_dim,8,padding=\"same\")(embedding_layer)\n","conv_out=Activation(\"relu\")(conv_out)\n","conv_out=Conv1D(value_dim,8,activation=\"tanh\",padding=\"same\")(conv_out)\n","\n","#Mecanismo de attention\n","#Producto punto y la salida hacia una softmax\n","ulog_attention=Dense(1,activation=\"linear\")(conv_out)\n","repeated_attention=Flatten()(ulog_attention)\n","softmax=Activation('softmax')(repeated_attention)\n","reshape=Reshape([500, 1])(softmax)\n","#obtengo los embeddings pesados\n","weighted_embeddings=Multiply()([reshape,conv_out])\n","#Sumo las salidas para crear la representacion vectorial del texto\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n","\n","#MLP\n","dense1=Dense(100, activation='relu')(embedding_sum)\n","dense2=Dense(20, activation='softmax')(dense1)\n","model=Model(input_layer , dense2)\n","\n","adam = optimizers.Adam(learning_rate=0.001)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":455,"status":"ok","timestamp":1695929313915,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"iiX7RdoqJwJQ","outputId":"09fccf92-45bc-42fa-a455-4932dd2d60ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 500)]                0         []                            \n","                                                                                                  \n"," embedding_1 (Embedding)     (None, 500, 300)             4024320   ['input_2[0][0]']             \n","                                                          0                                       \n","                                                                                                  \n"," conv1d_2 (Conv1D)           (None, 500, 100)             240100    ['embedding_1[0][0]']         \n","                                                                                                  \n"," activation_2 (Activation)   (None, 500, 100)             0         ['conv1d_2[0][0]']            \n","                                                                                                  \n"," conv1d_3 (Conv1D)           (None, 500, 100)             80100     ['activation_2[0][0]']        \n","                                                                                                  \n"," dense_1 (Dense)             (None, 500, 1)               101       ['conv1d_3[0][0]']            \n","                                                                                                  \n"," flatten (Flatten)           (None, 500)                  0         ['dense_1[0][0]']             \n","                                                                                                  \n"," activation_3 (Activation)   (None, 500)                  0         ['flatten[0][0]']             \n","                                                                                                  \n"," reshape_1 (Reshape)         (None, 500, 1)               0         ['activation_3[0][0]']        \n","                                                                                                  \n"," multiply_1 (Multiply)       (None, 500, 100)             0         ['reshape_1[0][0]',           \n","                                                                     'conv1d_3[0][0]']            \n","                                                                                                  \n"," lambda (Lambda)             (None, 100)                  0         ['multiply_1[0][0]']          \n","                                                                                                  \n"," dense_2 (Dense)             (None, 100)                  10100     ['lambda[0][0]']              \n","                                                                                                  \n"," dense_3 (Dense)             (None, 20)                   2020      ['dense_2[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 40575621 (154.78 MB)\n","Trainable params: 332421 (1.27 MB)\n","Non-trainable params: 40243200 (153.52 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143445,"status":"ok","timestamp":1695929472786,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"4h9nMGuUNiF9","outputId":"3d7fc01f-42be-4351-dc6c-415461c15c8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","283/283 [==============================] - 17s 18ms/step - loss: 1.4621 - accuracy: 0.5181 - val_loss: 0.8256 - val_accuracy: 0.7340\n","Epoch 2/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.5796 - accuracy: 0.8108 - val_loss: 0.6516 - val_accuracy: 0.7852\n","Epoch 3/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.3619 - accuracy: 0.8855 - val_loss: 0.5991 - val_accuracy: 0.8184\n","Epoch 4/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.2348 - accuracy: 0.9280 - val_loss: 0.6091 - val_accuracy: 0.8193\n","Epoch 5/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.1484 - accuracy: 0.9525 - val_loss: 0.5908 - val_accuracy: 0.8396\n","Epoch 6/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.1003 - accuracy: 0.9704 - val_loss: 0.6989 - val_accuracy: 0.8294\n","Epoch 7/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.7147 - val_accuracy: 0.8356\n","Epoch 8/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.7621 - val_accuracy: 0.8392\n","Epoch 9/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.0506 - accuracy: 0.9854 - val_loss: 0.8175 - val_accuracy: 0.8387\n","Epoch 10/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.8340 - val_accuracy: 0.8427\n","Epoch 11/20\n","283/283 [==============================] - 5s 18ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.8493 - val_accuracy: 0.8471\n","Epoch 12/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.0324 - accuracy: 0.9901 - val_loss: 0.9759 - val_accuracy: 0.8237\n","Epoch 13/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.9591 - val_accuracy: 0.8303\n","Epoch 14/20\n","283/283 [==============================] - 6s 21ms/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 0.8879 - val_accuracy: 0.8445\n","Epoch 15/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.8750 - val_accuracy: 0.8484\n","Epoch 16/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.9232 - val_accuracy: 0.8369\n","Epoch 17/20\n","283/283 [==============================] - 5s 18ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.9902 - val_accuracy: 0.8400\n","Epoch 18/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.9660 - val_accuracy: 0.8378\n","Epoch 19/20\n","283/283 [==============================] - 5s 19ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.9458 - val_accuracy: 0.8445\n","Epoch 20/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.0117 - val_accuracy: 0.8445\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7cc21153d600>"]},"metadata":{},"execution_count":11}],"source":["model.fit(train_sequences, newsgroups_train.target,batch_size=32,epochs=20,validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"ffDrPMYtqVv0"},"source":["## Red Attention + Bidirectional LSTM\n","\n","Se reemplaza la parte convolucional de la red con una capa LSTM Bidireccional para obtener otro tipo de representacion de cada palabra con el contexto del resto del texto. Dada la bidireccionalidad se obtiene contexto para la palabra desde las palabras anteriores y las posteriores."]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":50651,"status":"ok","timestamp":1695933079166,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"NdBid0lUNxID","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f395585-a2ba-4d79-aac8-68a2346235f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["value_dim=50\n","nb_words=num_words\n","num_filters=64\n","input_layer = Input(shape=(max_len,))\n","embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n","\n","#Bidirectional LSTM\n","lstm_out=Bidirectional(LSTM(value_dim, return_sequences=True,activation=\"tanh\", unroll=True), merge_mode=\"mul\")(embedding_layer)\n","lstm_out=Dropout(0.3)(lstm_out)\n","\n","#Mecanismo de attention\n","\n","ulog_attention=Dense(1,activation=\"linear\")(lstm_out)\n","repeated_attention=Flatten()(ulog_attention)\n","softmax=Activation('softmax')(repeated_attention)\n","reshape=Reshape([500, 1])(softmax)\n","weighted_embeddings=Multiply()([reshape,lstm_out])\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n","\n","\n","#MLP\n","dense1=Dense(100, activation='relu')(embedding_sum)\n","dense2=Dense(20, activation='softmax')(dense1)\n","model=Model(input_layer , dense2)\n","\n","#adam = optimizers.Adam(learning_rate=0.001)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1695933079166,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"jGzGu5lfZ-QV","outputId":"42a3d9ef-b35c-4462-c613-6353bad124e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_8 (InputLayer)        [(None, 500)]                0         []                            \n","                                                                                                  \n"," embedding_7 (Embedding)     (None, 500, 300)             4024320   ['input_8[0][0]']             \n","                                                          0                                       \n","                                                                                                  \n"," bidirectional_5 (Bidirecti  (None, 500, 50)              140400    ['embedding_7[0][0]']         \n"," onal)                                                                                            \n","                                                                                                  \n"," dropout (Dropout)           (None, 500, 50)              0         ['bidirectional_5[0][0]']     \n","                                                                                                  \n"," dense_19 (Dense)            (None, 500, 1)               51        ['dropout[0][0]']             \n","                                                                                                  \n"," flatten_6 (Flatten)         (None, 500)                  0         ['dense_19[0][0]']            \n","                                                                                                  \n"," activation_9 (Activation)   (None, 500)                  0         ['flatten_6[0][0]']           \n","                                                                                                  \n"," reshape_7 (Reshape)         (None, 500, 1)               0         ['activation_9[0][0]']        \n","                                                                                                  \n"," multiply_7 (Multiply)       (None, 500, 50)              0         ['reshape_7[0][0]',           \n","                                                                     'dropout[0][0]']             \n","                                                                                                  \n"," lambda_6 (Lambda)           (None, 50)                   0         ['multiply_7[0][0]']          \n","                                                                                                  \n"," dense_20 (Dense)            (None, 100)                  5100      ['lambda_6[0][0]']            \n","                                                                                                  \n"," dense_21 (Dense)            (None, 20)                   2020      ['dense_20[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 40390771 (154.08 MB)\n","Trainable params: 147571 (576.45 KB)\n","Non-trainable params: 40243200 (153.52 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","source":["model.fit(train_sequences, newsgroups_train.target,batch_size=128,epochs=40,validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4NHnJo737uBv","executionInfo":{"status":"ok","timestamp":1695934828490,"user_tz":180,"elapsed":1744147,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"}},"outputId":"5a9f9cdd-796c-44d6-b726-81153c2d6a37"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","71/71 [==============================] - 374s 1s/step - loss: 2.9922 - accuracy: 0.0640 - val_loss: 2.9859 - val_accuracy: 0.0689\n","Epoch 2/40\n","71/71 [==============================] - 35s 500ms/step - loss: 2.8161 - accuracy: 0.0941 - val_loss: 2.5931 - val_accuracy: 0.1370\n","Epoch 3/40\n","71/71 [==============================] - 36s 511ms/step - loss: 2.5370 - accuracy: 0.1610 - val_loss: 2.4136 - val_accuracy: 0.1856\n","Epoch 4/40\n","71/71 [==============================] - 39s 549ms/step - loss: 2.2366 - accuracy: 0.2445 - val_loss: 2.0101 - val_accuracy: 0.2762\n","Epoch 5/40\n","71/71 [==============================] - 36s 507ms/step - loss: 1.8791 - accuracy: 0.3519 - val_loss: 1.7578 - val_accuracy: 0.4282\n","Epoch 6/40\n","71/71 [==============================] - 35s 500ms/step - loss: 1.5676 - accuracy: 0.4670 - val_loss: 1.6098 - val_accuracy: 0.4238\n","Epoch 7/40\n","71/71 [==============================] - 39s 544ms/step - loss: 1.3118 - accuracy: 0.5483 - val_loss: 1.2338 - val_accuracy: 0.5833\n","Epoch 8/40\n","71/71 [==============================] - 37s 526ms/step - loss: 1.1283 - accuracy: 0.6072 - val_loss: 1.1092 - val_accuracy: 0.6204\n","Epoch 9/40\n","71/71 [==============================] - 36s 511ms/step - loss: 0.9989 - accuracy: 0.6643 - val_loss: 0.9999 - val_accuracy: 0.6597\n","Epoch 10/40\n","71/71 [==============================] - 33s 468ms/step - loss: 0.8896 - accuracy: 0.6998 - val_loss: 0.9142 - val_accuracy: 0.7053\n","Epoch 11/40\n","71/71 [==============================] - 26s 369ms/step - loss: 0.7962 - accuracy: 0.7340 - val_loss: 0.8186 - val_accuracy: 0.7234\n","Epoch 12/40\n","71/71 [==============================] - 26s 369ms/step - loss: 0.6969 - accuracy: 0.7662 - val_loss: 0.8864 - val_accuracy: 0.7137\n","Epoch 13/40\n","71/71 [==============================] - 26s 370ms/step - loss: 0.6370 - accuracy: 0.7890 - val_loss: 0.7972 - val_accuracy: 0.7357\n","Epoch 14/40\n","71/71 [==============================] - 27s 380ms/step - loss: 0.5798 - accuracy: 0.8067 - val_loss: 0.7214 - val_accuracy: 0.7671\n","Epoch 15/40\n","71/71 [==============================] - 29s 404ms/step - loss: 0.5297 - accuracy: 0.8270 - val_loss: 0.6579 - val_accuracy: 0.7883\n","Epoch 16/40\n","71/71 [==============================] - 35s 499ms/step - loss: 0.4821 - accuracy: 0.8430 - val_loss: 0.6770 - val_accuracy: 0.7835\n","Epoch 17/40\n","71/71 [==============================] - 36s 511ms/step - loss: 0.4420 - accuracy: 0.8550 - val_loss: 0.6180 - val_accuracy: 0.8060\n","Epoch 18/40\n","71/71 [==============================] - 39s 544ms/step - loss: 0.4115 - accuracy: 0.8673 - val_loss: 0.6142 - val_accuracy: 0.8087\n","Epoch 19/40\n","71/71 [==============================] - 36s 511ms/step - loss: 0.3774 - accuracy: 0.8766 - val_loss: 0.6184 - val_accuracy: 0.8038\n","Epoch 20/40\n","71/71 [==============================] - 37s 525ms/step - loss: 0.3516 - accuracy: 0.8889 - val_loss: 0.6079 - val_accuracy: 0.8091\n","Epoch 21/40\n","71/71 [==============================] - 39s 547ms/step - loss: 0.3192 - accuracy: 0.8965 - val_loss: 0.6235 - val_accuracy: 0.8104\n","Epoch 22/40\n","71/71 [==============================] - 35s 496ms/step - loss: 0.3016 - accuracy: 0.9034 - val_loss: 0.6066 - val_accuracy: 0.8188\n","Epoch 23/40\n","71/71 [==============================] - 35s 491ms/step - loss: 0.2859 - accuracy: 0.9111 - val_loss: 0.5840 - val_accuracy: 0.8219\n","Epoch 24/40\n","71/71 [==============================] - 36s 505ms/step - loss: 0.2617 - accuracy: 0.9158 - val_loss: 0.6095 - val_accuracy: 0.8241\n","Epoch 25/40\n","71/71 [==============================] - 38s 542ms/step - loss: 0.2402 - accuracy: 0.9244 - val_loss: 0.6523 - val_accuracy: 0.8065\n","Epoch 26/40\n","71/71 [==============================] - 38s 529ms/step - loss: 0.2280 - accuracy: 0.9269 - val_loss: 0.6384 - val_accuracy: 0.8224\n","Epoch 27/40\n","71/71 [==============================] - 36s 510ms/step - loss: 0.2096 - accuracy: 0.9350 - val_loss: 0.6817 - val_accuracy: 0.8029\n","Epoch 28/40\n","71/71 [==============================] - 28s 399ms/step - loss: 0.1882 - accuracy: 0.9389 - val_loss: 0.6353 - val_accuracy: 0.8272\n","Epoch 29/40\n","71/71 [==============================] - 27s 381ms/step - loss: 0.1697 - accuracy: 0.9441 - val_loss: 0.6154 - val_accuracy: 0.8330\n","Epoch 30/40\n","71/71 [==============================] - 27s 377ms/step - loss: 0.1663 - accuracy: 0.9459 - val_loss: 0.6477 - val_accuracy: 0.8308\n","Epoch 31/40\n","71/71 [==============================] - 26s 368ms/step - loss: 0.1531 - accuracy: 0.9519 - val_loss: 0.6340 - val_accuracy: 0.8259\n","Epoch 32/40\n","71/71 [==============================] - 26s 373ms/step - loss: 0.1361 - accuracy: 0.9581 - val_loss: 0.6704 - val_accuracy: 0.8321\n","Epoch 33/40\n","71/71 [==============================] - 31s 440ms/step - loss: 0.1374 - accuracy: 0.9586 - val_loss: 0.6703 - val_accuracy: 0.8228\n","Epoch 34/40\n","71/71 [==============================] - 35s 490ms/step - loss: 0.1236 - accuracy: 0.9611 - val_loss: 0.6997 - val_accuracy: 0.8299\n","Epoch 35/40\n","71/71 [==============================] - 36s 504ms/step - loss: 0.1188 - accuracy: 0.9604 - val_loss: 0.6534 - val_accuracy: 0.8383\n","Epoch 36/40\n","71/71 [==============================] - 39s 555ms/step - loss: 0.1095 - accuracy: 0.9674 - val_loss: 0.6647 - val_accuracy: 0.8387\n","Epoch 37/40\n","71/71 [==============================] - 36s 511ms/step - loss: 0.1024 - accuracy: 0.9678 - val_loss: 0.6892 - val_accuracy: 0.8405\n","Epoch 38/40\n","71/71 [==============================] - 36s 505ms/step - loss: 0.1012 - accuracy: 0.9712 - val_loss: 0.7688 - val_accuracy: 0.8206\n","Epoch 39/40\n","71/71 [==============================] - 36s 514ms/step - loss: 0.0842 - accuracy: 0.9747 - val_loss: 0.7149 - val_accuracy: 0.8383\n","Epoch 40/40\n","71/71 [==============================] - 36s 513ms/step - loss: 0.0793 - accuracy: 0.9760 - val_loss: 0.7382 - val_accuracy: 0.8418\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7cc108225d20>"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Se puede finalizar observando que el uso de convoluciones vuelve el entrenamiento mas rapido aunque la red tiende a overfitting. en el caso del LSTM bidireccional, esta es de entrenamiento mas lento, incluso con el unroll=True, aunque se pueden encontrar mejores resultados."],"metadata":{"id":"FEpVWGGl5q5P"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNgtW8zlrYkxGCFBPTaUpze"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}