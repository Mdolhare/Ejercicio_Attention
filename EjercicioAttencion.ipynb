{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13807,"status":"ok","timestamp":1695606035366,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"m-4H1hfGCMK5"},"outputs":[],"source":["from sklearn.datasets import fetch_20newsgroups\n","from matplotlib import pyplot as plt\n","from collections import Counter\n","newsgroups_train = fetch_20newsgroups(subset='train')\n","newsgroups_test = fetch_20newsgroups(subset='test')\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import gensim\n","from gensim.models import KeyedVectors\n","import os, re, csv, math, codecs"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5780,"status":"ok","timestamp":1695606043631,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"DHkEhU4zCUmn"},"outputs":[],"source":["token=Tokenizer(num_words=30000,\n","                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n","                split=' ', char_level=False, oov_token=\"UNK\", document_count=0)\n","token.fit_on_texts(newsgroups_train.data)\n","train_sequences=token.texts_to_sequences(newsgroups_train.data)\n","test_sequences=token.texts_to_sequences(newsgroups_test.data)\n","lengths=[len(seq) for seq in train_sequences]\n","lengths=dict(Counter(lengths))\n","max_len=500 #Incluso si algunos textos son mas largos, tener las primeras 500 palabras es suficiente en la clasificacion de textos\n","train_sequences=pad_sequences(train_sequences,maxlen=max_len)   #Las primeras palabras suelen contener toda la informacion nesesaria para la clasificacion\n","test_sequences=pad_sequences(test_sequences,maxlen=max_len)\n","reverse_dictionary = token.index_word\n","dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2432,"status":"ok","timestamp":1695606046059,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"v7Y0eL8TCsNn","outputId":"05a9ca93-3aa5-42e7-e53b-9d8680308f18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60333,"status":"ok","timestamp":1695599718349,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"qUEoCGLMCstu","outputId":"0e4387ff-cfca-4a6b-9692-5561fd42af5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  drive/MyDrive/crawl-300d-2M.vec.zip\n","  inflating: crawl-300d-2M.vec       \n"]}],"source":["!unzip 'drive/MyDrive/crawl-300d-2M.vec.zip'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":454064,"status":"ok","timestamp":1695606503872,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"oSEC-PPVC1fB"},"outputs":[],"source":["#Se utilizan los embeddigns de facebook pre-entrenados con Common Crawl\n","embeddings_index = KeyedVectors.load_word2vec_format('crawl-300d-2M.vec',\n","                                                     binary=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":865,"status":"ok","timestamp":1695606504726,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"ctACqILWC3Ry"},"outputs":[],"source":["embed_dim=300\n","num_words=len(dictionary)+1\n","embedding_matrix=np.zeros([num_words,embed_dim])\n","for word, idx in dictionary.items():\n","  if idx <= num_words and word in embeddings_index:\n","    embedding_matrix[idx,:]=embeddings_index[word]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1695606504731,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"1y53XiOkE6QM"},"outputs":[],"source":["from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, MaxPooling1D, Dropout, Dense, Input, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Flatten, BatchNormalization, Activation, Bidirectional, LSTM, Reshape\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.activations import softmax\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import optimizers"]},{"cell_type":"markdown","metadata":{"id":"PQK19DbyP1Ll"},"source":["# Red de attention + conv\n","### Parte convolucional:\n","Se utiliza una red convolucional luego de la capa de embeddings para optener una representacion de la palabra que incluya su contexto, es decir que a la salida se tienen vectores de dimencion 100 los cuales puede comprender un significado de la palabra en base a las palabras en su alrededor. La funcion tangente hyperbolica a la salida de la ultima capa convolucional se utiliza para escalar la salida. Se quiere valores pequeÃ±os a la salida para evitar problemas de baja gradiente en la funcion softmax.\n","\n","### Mecanismo de attention\n","Dado que se quiere clasificar en distintas clases, en este caso necesitamos un mequanismo que sepa reconocer que palabras son relevantes para la clasificacion y cuales no. Por lo tanto, hay solo una preguntar para hacer (si la palabra es relevante o no) y esto lleva a que haya un solo vector de query, el cual se obtiene durante el entrenamiento de la capa.\n","Luego de obtener la representacion ponderada de cada palabra estas se suman para obtener la representacion ponderada del texto completo. No es necesario dividir el total por la cantidad de palabras ya que en el preprocesamiento se dejaron todos los vectores de textos con la misma dimencionalidad.\n","\n"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":483,"status":"ok","timestamp":1695604356143,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"jO1pjpewC5Qv"},"outputs":[],"source":["value_dim=100\n","nb_words=num_words\n","num_filters=64\n","input_layer = Input(shape=(max_len,))\n","embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n","\n","#Capa convolucional\n","conv_out=Conv1D(value_dim,8,padding=\"same\")(embedding_layer)\n","conv_out=Activation(\"relu\")(conv_out)\n","conv_out=Conv1D(value_dim,8,activation=\"tanh\",padding=\"same\")(conv_out)\n","\n","#Mecanismo de attention\n","#Producto punto y la salida hacia una softmax\n","ulog_attention=Dense(1,activation=\"softmax\")(conv_out)\n","#obtengo los embeddings pesados\n","weighted_embeddings=Multiply()([ulog_attention,conv_out])\n","#Sumo las salidas para crear la representacion vectorial del texto\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n","\n","#MLP\n","dense1=Dense(100, activation='relu')(embedding_sum)\n","dense2=Dense(20, activation='softmax')(dense1)\n","model=Model(input_layer , dense2)\n","\n","adam = optimizers.Adam(learning_rate=0.001)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1695604356144,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"iiX7RdoqJwJQ","outputId":"910bf4e1-14f7-4259-87d9-957da801dfd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_18\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_22 (InputLayer)       [(None, 500)]                0         []                            \n","                                                                                                  \n"," embedding_21 (Embedding)    (None, 500, 300)             4024320   ['input_22[0][0]']            \n","                                                          0                                       \n","                                                                                                  \n"," conv1d_55 (Conv1D)          (None, 500, 100)             240100    ['embedding_21[0][0]']        \n","                                                                                                  \n"," activation_3 (Activation)   (None, 500, 100)             0         ['conv1d_55[0][0]']           \n","                                                                                                  \n"," conv1d_56 (Conv1D)          (None, 500, 100)             80100     ['activation_3[0][0]']        \n","                                                                                                  \n"," dense_50 (Dense)            (None, 500, 1)               101       ['conv1d_56[0][0]']           \n","                                                                                                  \n"," multiply_19 (Multiply)      (None, 500, 100)             0         ['dense_50[0][0]',            \n","                                                                     'conv1d_56[0][0]']           \n","                                                                                                  \n"," lambda_19 (Lambda)          (None, 100)                  0         ['multiply_19[0][0]']         \n","                                                                                                  \n"," dense_51 (Dense)            (None, 100)                  10100     ['lambda_19[0][0]']           \n","                                                                                                  \n"," dense_52 (Dense)            (None, 20)                   2020      ['dense_51[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 40575621 (154.78 MB)\n","Trainable params: 332421 (1.27 MB)\n","Non-trainable params: 40243200 (153.52 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263259,"status":"ok","timestamp":1695604619395,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"4h9nMGuUNiF9","outputId":"6c7f8d14-6328-49ee-dc5f-c663e31f0b35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","283/283 [==============================] - 7s 17ms/step - loss: 3.7031 - accuracy: 0.4638 - val_loss: 1.1941 - val_accuracy: 0.6487\n","Epoch 2/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.9298 - accuracy: 0.7309 - val_loss: 0.7910 - val_accuracy: 0.7640\n","Epoch 3/20\n","283/283 [==============================] - 4s 16ms/step - loss: 0.6040 - accuracy: 0.8227 - val_loss: 0.6573 - val_accuracy: 0.8091\n","Epoch 4/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.4028 - accuracy: 0.8845 - val_loss: 0.7606 - val_accuracy: 0.8016\n","Epoch 5/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.3277 - accuracy: 0.9059 - val_loss: 0.6420 - val_accuracy: 0.8272\n","Epoch 6/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.2558 - accuracy: 0.9292 - val_loss: 0.6380 - val_accuracy: 0.8471\n","Epoch 7/20\n","283/283 [==============================] - 176s 624ms/step - loss: 0.1703 - accuracy: 0.9508 - val_loss: 0.6199 - val_accuracy: 0.8405\n","Epoch 8/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.1467 - accuracy: 0.9602 - val_loss: 0.6325 - val_accuracy: 0.8529\n","Epoch 9/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.1219 - accuracy: 0.9697 - val_loss: 0.6251 - val_accuracy: 0.8498\n","Epoch 10/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.1024 - accuracy: 0.9733 - val_loss: 0.6657 - val_accuracy: 0.8471\n","Epoch 11/20\n","283/283 [==============================] - 5s 17ms/step - loss: 0.1084 - accuracy: 0.9692 - val_loss: 0.9452 - val_accuracy: 0.8246\n","Epoch 12/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.1336 - accuracy: 0.9691 - val_loss: 0.7957 - val_accuracy: 0.8440\n","Epoch 13/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.1107 - accuracy: 0.9698 - val_loss: 0.8789 - val_accuracy: 0.8352\n","Epoch 14/20\n","283/283 [==============================] - 5s 16ms/step - loss: 0.1408 - accuracy: 0.9671 - val_loss: 0.8278 - val_accuracy: 0.8467\n","Epoch 15/20\n","283/283 [==============================] - 4s 16ms/step - loss: 0.0962 - accuracy: 0.9747 - val_loss: 0.9916 - val_accuracy: 0.8272\n","Epoch 16/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.0760 - accuracy: 0.9782 - val_loss: 1.1872 - val_accuracy: 0.8153\n","Epoch 17/20\n","283/283 [==============================] - 4s 16ms/step - loss: 0.1419 - accuracy: 0.9628 - val_loss: 0.9749 - val_accuracy: 0.8299\n","Epoch 18/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.8761 - val_accuracy: 0.8595\n","Epoch 19/20\n","283/283 [==============================] - 4s 15ms/step - loss: 0.0568 - accuracy: 0.9857 - val_loss: 0.9190 - val_accuracy: 0.8515\n","Epoch 20/20\n","283/283 [==============================] - 4s 16ms/step - loss: 0.1150 - accuracy: 0.9735 - val_loss: 1.5237 - val_accuracy: 0.7799\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c0ba8177cd0>"]},"metadata":{},"execution_count":65}],"source":["model.fit(train_sequences, newsgroups_train.target,batch_size=32,epochs=20,validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"ffDrPMYtqVv0"},"source":["## Red Attention + Bidirectional LSTM\n","\n","Se reemplaza la parte convolucional de la red con una capa LSTM Bidireccional para obtener otro tipo de representacion de cada palabra con el contexto del resto del texto. Dada la bidireccionalidad se obtiene contexto para la palabra desde las palabras anteriores y las posteriores."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":14344,"status":"ok","timestamp":1695607650536,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"NdBid0lUNxID","colab":{"base_uri":"https://localhost:8080/"},"outputId":"304f11fe-c78c-4a71-b232-94c0fc378ea5"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["value_dim=100\n","nb_words=num_words\n","num_filters=64\n","input_layer = Input(shape=(max_len,))\n","embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n","\n","#Bidirectional LSTM\n","lstm_out=Bidirectional(LSTM(value_dim, return_sequences=True,activation=\"tanh\", unroll=True), merge_mode=\"mul\")(embedding_layer)\n","\n","def softMaxOverTime(x):\n","    return softmax(x,axis=1)\n","\n","#Mecanismo de attention\n","\n","ulog_attention=Dense(1,activation=\"linear\")(lstm_out)\n","attention=Activation(softMaxOverTime)(ulog_attention)\n","repeated_attention=TimeDistributed(RepeatVector(value_dim))(attention)\n","repeated_attention=Reshape([max_len,value_dim])(repeated_attention)\n","weighted_embeddings=Multiply()([repeated_attention,lstm_out])\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n","\n","#MLP\n","dense1=Dense(100, activation='relu')(embedding_sum)\n","dense2=Dense(20, activation='softmax')(dense1)\n","model=Model(input_layer , dense2)\n","\n","adam = optimizers.Adam(learning_rate=0.001)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1695607650538,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"},"user_tz":180},"id":"jGzGu5lfZ-QV","outputId":"e38e8a9c-6ce6-4992-9109-d18e8afa7569"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 500)]                0         []                            \n","                                                                                                  \n"," embedding_1 (Embedding)     (None, 500, 300)             4024320   ['input_2[0][0]']             \n","                                                          0                                       \n","                                                                                                  \n"," bidirectional (Bidirection  (None, 500, 100)             320800    ['embedding_1[0][0]']         \n"," al)                                                                                              \n","                                                                                                  \n"," dense (Dense)               (None, 500, 1)               101       ['bidirectional[0][0]']       \n","                                                                                                  \n"," activation (Activation)     (None, 500, 1)               0         ['dense[0][0]']               \n","                                                                                                  \n"," time_distributed (TimeDist  (None, 500, 100, 1)          0         ['activation[0][0]']          \n"," ributed)                                                                                         \n","                                                                                                  \n"," reshape (Reshape)           (None, 500, 100)             0         ['time_distributed[0][0]']    \n","                                                                                                  \n"," multiply (Multiply)         (None, 500, 100)             0         ['reshape[0][0]',             \n","                                                                     'bidirectional[0][0]']       \n","                                                                                                  \n"," lambda (Lambda)             (None, 100)                  0         ['multiply[0][0]']            \n","                                                                                                  \n"," dense_1 (Dense)             (None, 100)                  10100     ['lambda[0][0]']              \n","                                                                                                  \n"," dense_2 (Dense)             (None, 20)                   2020      ['dense_1[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 40576221 (154.79 MB)\n","Trainable params: 333021 (1.27 MB)\n","Non-trainable params: 40243200 (153.52 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","source":["model.fit(train_sequences, newsgroups_train.target,batch_size=516,epochs=40,validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4NHnJo737uBv","executionInfo":{"status":"ok","timestamp":1695608287667,"user_tz":180,"elapsed":637138,"user":{"displayName":"MARIANO AGUSTIN DOLHARE","userId":"02083329923890892529"}},"outputId":"be3dce2a-b83f-43c0-8067-59fea78846d9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","18/18 [==============================] - 280s 2s/step - loss: 2.9725 - accuracy: 0.0963 - val_loss: 2.8533 - val_accuracy: 0.1255\n","Epoch 2/40\n","18/18 [==============================] - 8s 445ms/step - loss: 2.6864 - accuracy: 0.1463 - val_loss: 2.4579 - val_accuracy: 0.2117\n","Epoch 3/40\n","18/18 [==============================] - 7s 385ms/step - loss: 2.2540 - accuracy: 0.2569 - val_loss: 2.1327 - val_accuracy: 0.2581\n","Epoch 4/40\n","18/18 [==============================] - 8s 473ms/step - loss: 1.9853 - accuracy: 0.3305 - val_loss: 1.8137 - val_accuracy: 0.4114\n","Epoch 5/40\n","18/18 [==============================] - 8s 474ms/step - loss: 1.6846 - accuracy: 0.4235 - val_loss: 1.5677 - val_accuracy: 0.4490\n","Epoch 6/40\n","18/18 [==============================] - 9s 532ms/step - loss: 1.4781 - accuracy: 0.4882 - val_loss: 1.4408 - val_accuracy: 0.4932\n","Epoch 7/40\n","18/18 [==============================] - 9s 493ms/step - loss: 1.3161 - accuracy: 0.5360 - val_loss: 1.2576 - val_accuracy: 0.5647\n","Epoch 8/40\n","18/18 [==============================] - 9s 499ms/step - loss: 1.1706 - accuracy: 0.5879 - val_loss: 1.1406 - val_accuracy: 0.5983\n","Epoch 9/40\n","18/18 [==============================] - 10s 543ms/step - loss: 1.0851 - accuracy: 0.6179 - val_loss: 1.1430 - val_accuracy: 0.5952\n","Epoch 10/40\n","18/18 [==============================] - 8s 456ms/step - loss: 0.9871 - accuracy: 0.6510 - val_loss: 1.0271 - val_accuracy: 0.6513\n","Epoch 11/40\n","18/18 [==============================] - 10s 578ms/step - loss: 0.8970 - accuracy: 0.6880 - val_loss: 0.9285 - val_accuracy: 0.6858\n","Epoch 12/40\n","18/18 [==============================] - 9s 499ms/step - loss: 0.8124 - accuracy: 0.7220 - val_loss: 0.8784 - val_accuracy: 0.7044\n","Epoch 13/40\n","18/18 [==============================] - 9s 513ms/step - loss: 0.7322 - accuracy: 0.7590 - val_loss: 0.8441 - val_accuracy: 0.7251\n","Epoch 14/40\n","18/18 [==============================] - 9s 529ms/step - loss: 0.6632 - accuracy: 0.7817 - val_loss: 0.8025 - val_accuracy: 0.7353\n","Epoch 15/40\n","18/18 [==============================] - 8s 467ms/step - loss: 0.6410 - accuracy: 0.7860 - val_loss: 0.8048 - val_accuracy: 0.7309\n","Epoch 16/40\n","18/18 [==============================] - 10s 587ms/step - loss: 0.5855 - accuracy: 0.8084 - val_loss: 0.7217 - val_accuracy: 0.7676\n","Epoch 17/40\n","18/18 [==============================] - 9s 488ms/step - loss: 0.5259 - accuracy: 0.8323 - val_loss: 0.7299 - val_accuracy: 0.7631\n","Epoch 18/40\n","18/18 [==============================] - 10s 528ms/step - loss: 0.4825 - accuracy: 0.8430 - val_loss: 0.7040 - val_accuracy: 0.7746\n","Epoch 19/40\n","18/18 [==============================] - 10s 575ms/step - loss: 0.4567 - accuracy: 0.8528 - val_loss: 0.6931 - val_accuracy: 0.7786\n","Epoch 20/40\n","18/18 [==============================] - 9s 483ms/step - loss: 0.4060 - accuracy: 0.8711 - val_loss: 0.6879 - val_accuracy: 0.7791\n","Epoch 21/40\n","18/18 [==============================] - 10s 536ms/step - loss: 0.3764 - accuracy: 0.8827 - val_loss: 0.6943 - val_accuracy: 0.7852\n","Epoch 22/40\n","18/18 [==============================] - 10s 558ms/step - loss: 0.3585 - accuracy: 0.8870 - val_loss: 0.6784 - val_accuracy: 0.7897\n","Epoch 23/40\n","18/18 [==============================] - 8s 442ms/step - loss: 0.3215 - accuracy: 0.9021 - val_loss: 0.8623 - val_accuracy: 0.7406\n","Epoch 24/40\n","18/18 [==============================] - 10s 535ms/step - loss: 0.5875 - accuracy: 0.8133 - val_loss: 0.6996 - val_accuracy: 0.7715\n","Epoch 25/40\n","18/18 [==============================] - 9s 503ms/step - loss: 0.4237 - accuracy: 0.8693 - val_loss: 0.6543 - val_accuracy: 0.7892\n","Epoch 26/40\n","18/18 [==============================] - 9s 516ms/step - loss: 0.3281 - accuracy: 0.9013 - val_loss: 0.6136 - val_accuracy: 0.8104\n","Epoch 27/40\n","18/18 [==============================] - 10s 573ms/step - loss: 0.2892 - accuracy: 0.9105 - val_loss: 0.6471 - val_accuracy: 0.8007\n","Epoch 28/40\n","18/18 [==============================] - 9s 480ms/step - loss: 0.2616 - accuracy: 0.9208 - val_loss: 0.6665 - val_accuracy: 0.7981\n","Epoch 29/40\n","18/18 [==============================] - 10s 544ms/step - loss: 0.2295 - accuracy: 0.9344 - val_loss: 0.6692 - val_accuracy: 0.8047\n","Epoch 30/40\n","18/18 [==============================] - 10s 551ms/step - loss: 0.2022 - accuracy: 0.9408 - val_loss: 0.6548 - val_accuracy: 0.8091\n","Epoch 31/40\n","18/18 [==============================] - 9s 497ms/step - loss: 0.1718 - accuracy: 0.9533 - val_loss: 0.6423 - val_accuracy: 0.8095\n","Epoch 32/40\n","18/18 [==============================] - 9s 523ms/step - loss: 0.1679 - accuracy: 0.9530 - val_loss: 0.6727 - val_accuracy: 0.8038\n","Epoch 33/40\n","18/18 [==============================] - 9s 505ms/step - loss: 0.1590 - accuracy: 0.9569 - val_loss: 0.6824 - val_accuracy: 0.8034\n","Epoch 34/40\n","18/18 [==============================] - 9s 493ms/step - loss: 0.1476 - accuracy: 0.9591 - val_loss: 0.6850 - val_accuracy: 0.8078\n","Epoch 35/40\n","18/18 [==============================] - 10s 576ms/step - loss: 0.1430 - accuracy: 0.9612 - val_loss: 0.6894 - val_accuracy: 0.8065\n","Epoch 36/40\n","18/18 [==============================] - 9s 494ms/step - loss: 0.1256 - accuracy: 0.9677 - val_loss: 0.6938 - val_accuracy: 0.8109\n","Epoch 37/40\n","18/18 [==============================] - 9s 522ms/step - loss: 0.1225 - accuracy: 0.9684 - val_loss: 0.6908 - val_accuracy: 0.8126\n","Epoch 38/40\n","18/18 [==============================] - 10s 550ms/step - loss: 0.0888 - accuracy: 0.9791 - val_loss: 0.7073 - val_accuracy: 0.8100\n","Epoch 39/40\n","18/18 [==============================] - 8s 463ms/step - loss: 0.0724 - accuracy: 0.9841 - val_loss: 0.7060 - val_accuracy: 0.8162\n","Epoch 40/40\n","18/18 [==============================] - 10s 572ms/step - loss: 0.0662 - accuracy: 0.9870 - val_loss: 0.7966 - val_accuracy: 0.8082\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7e7e04bfc280>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Se puede finalizar observando que el uso de convoluciones vuelve el entrenamiento mas rapido aunque la red tienede a overfitting. en el caso del LSTM bidireccional, esta es de entrenamiento mas lento, incluso con el unroll=True, aunque se pueden encontrar mejores resultados."],"metadata":{"id":"FEpVWGGl5q5P"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyN8yoB2bYcwgnon244HemfH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}